{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1lqCH4jKzrYLz9BvXamuh6GrA3cbDa2iQ","timestamp":1664413393329}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["5578eed376e54ab5a3e271e50cad3a2d","3213e5cbfe9541739e5e3c370e7f5f8f","a95e01a980d649a19dc316b2e7ae8a73","7919762bba1b43cebe1412bb27c054c4","deaa66b467e3483ca17ec028701b487b","8f3c2e4ad79649c18a736922451c3ed6","107e67aa1e2046c392c1042c8f0fbc75","b6da020702984f6ebe04e146f04ceae3","ad3a0d6a5a89482c8a132fa23f924e77","7e0585d526324678af5900f4f0b5586c","5c287b3916a84d1891b3caf980d6dd32"]},"id":"krW9fSgG_jph","executionInfo":{"status":"ok","timestamp":1655027556658,"user_tz":-540,"elapsed":90809,"user":{"displayName":"강민정","userId":"10148478567047156743"}},"outputId":"8bc6919d-56b8-42a7-e329-f57d843dda10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ../stl10_binary.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2640397119 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5578eed376e54ab5a3e271e50cad3a2d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ../stl10_binary.tar.gz to ../\n","Files already downloaded and verified\n"]}],"source":["# 필요한 module import 및 trainset, testset 만들기\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.init as init\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","\n","import torchvision.models as models\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","trainset = dset.STL10(root=\"../\", split = \"train\", transform = transforms.ToTensor(), download = True)\n","testset = dset.STL10(root=\"../\", split = \"test\", transform = transforms.ToTensor(), download = True)\n","\n","# 이미지 96x96, color"]},{"cell_type":"markdown","metadata":{"id":"KAXr8OORBipv"},"source":["Problem 2 - 시도 1. Alexnet 구현\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XyoazU70BiMw"},"outputs":[],"source":["# 수업시간에 구현했던 모델이라 선택함. 주어진 데이터의 형태(3 x 96 x 96)에 맞게 변형하여 구현함.\n","\n","batch_size_1 = 32\n","learning_rate_1 = 0.0001\n","num_epoch = 50\n","\n","trainloader_1 = DataLoader(trainset, batch_size = batch_size_1)\n","testloader_1 = DataLoader(testset, batch_size = batch_size_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqfLK-SaCL86"},"outputs":[],"source":["class AlexNet_model1(nn.Module):\n","    def __init__(self):\n","        super(AlexNet_model1, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, 7), #[batch_size, 64, 90, 90]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2), #[batch_size, 64, 945, 45]\n","            nn.Conv2d(64, 192, 7),#[batch_size, 192, 39, 39]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2), #[batch_size, 192, 19, 19]\n","            nn.Conv2d(192, 384, 7),#[batch_size, 384, 13, 13]\n","            nn.ReLU(),\n","            nn.Conv2d(384, 256, 5),#[batch_size, 256, 9, 9]\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3),#[batch_size, 256, 7, 7]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2)) #[batch_size, 256, 3, 3]\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(256 * 3 * 3,1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(1024,512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10))\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(-1, 256 * 3 * 3)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vaMfoq4lCP3T"},"outputs":[],"source":["model1 = AlexNet_model1().to(device)\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model1.parameters(), lr = learning_rate_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psK3JstZCT8j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655026148526,"user_tz":-540,"elapsed":565033,"user":{"displayName":"강민정","userId":"10148478567047156743"}},"outputId":"76639e02-c4e5-433f-8ee3-bd4013da69b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.9206, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.3028, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.5702, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0760, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]}],"source":["for i in range(num_epoch):\n","    for j, [image, label] in enumerate(trainloader_1):\n","        x = image.to(device)\n","        y_ = label.to(device)\n","\n","        optimizer.zero_grad()\n","        output = model1.forward(x)\n","        loss = loss_func(output, y_)\n","        loss.backward()\n","        optimizer.step()\n","    if i % 10 == 0:\n","        print(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sw1VA5tYCUeG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655026158450,"user_tz":-540,"elapsed":9944,"user":{"displayName":"강민정","userId":"10148478567047156743"}},"outputId":"31616b46-f7c3-4ef3-a59a-e11d809aa3b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["model1 accuracy :  55.0125\n"]}],"source":["correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    model1.eval()\n","    for data in testloader_1:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        outputs = model1(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print(\"model1 accuracy : \", 100 * correct / total)"]},{"cell_type":"markdown","metadata":{"id":"fBZXu-oSCdZp"},"source":["Problem 2 - 시도 2. Alexnet 구현\n","\n","\n","*   padding 사용\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rC2bPs2ZDDv4"},"outputs":[],"source":["# 첫 번째 시도에서 padding을 이용하지 않아 padding을 사용했을 때의 성능의 변화가 궁금함.\n","\n","batch_size_2 = 32\n","learning_rate_2 = 0.0001\n","num_epoch = 50\n","\n","trainloader_2 = DataLoader(trainset, batch_size = batch_size_2)\n","testloader_2 = DataLoader(testset, batch_size = batch_size_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ekmpq4h1C9f3"},"outputs":[],"source":["class AlexNet_model2(nn.Module):\n","    def __init__(self):\n","        super(AlexNet_model2, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, 7), #[batch_size, 64, 90, 90]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2), #[batch_size, 64, 45, 45]\n","            nn.Conv2d(64, 192, 7, padding = 1), #[batch_size, 192, 41, 41]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2), #[batch_size, 192, 20, 20]\n","            nn.Conv2d(192, 384, 7, padding = 1), #[batch_size, 384, 16, 16]\n","            nn.ReLU(),\n","            nn.Conv2d(384, 256, 5, padding = 1), #[batch_size, 256, 14, 14]\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3), #[batch_size, 256, 12, 12]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2)) #[batch_size, 256, 6, 6]\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(256 * 6 * 6,1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(1024,512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10))\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(-1, 256 * 6 * 6)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GlYYKtkEC-Cw"},"outputs":[],"source":["model2 = AlexNet_model2().to(device)\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model2.parameters(), lr = learning_rate_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ewn2uCjIC_1R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655026850323,"user_tz":-540,"elapsed":691884,"user":{"displayName":"강민정","userId":"10148478567047156743"}},"outputId":"5531a588-0ba6-4a0f-f881-fa647250f8c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.8699, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.9101, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]}],"source":["for i in range(num_epoch):\n","    for j, [image, label] in enumerate(trainloader_2):\n","        x = image.to(device)\n","        y_ = label.to(device)\n","\n","        optimizer.zero_grad()\n","        output = model2.forward(x)\n","        loss = loss_func(output, y_)\n","        loss.backward()\n","        optimizer.step()\n","    if i % 10 == 0:\n","        print(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AtfmW08TDBIH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655026861456,"user_tz":-540,"elapsed":11144,"user":{"displayName":"강민정","userId":"10148478567047156743"}},"outputId":"38cb9cf3-0364-46a9-94fe-24e999dd4265"},"outputs":[{"output_type":"stream","name":"stdout","text":["model2 accuracy :  57.2\n"]}],"source":["correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    model2.eval()\n","    for data in testloader_2:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        outputs = model2(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print(\"model2 accuracy : \", 100 * correct / total)"]},{"cell_type":"markdown","metadata":{"id":"3LWCP1xjE0I2"},"source":["Problem 2 - 시도3. Alexnet 구현\n","\n","\n","*   padding 사용\n","*   배치사이즈 키움\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCT3SfltE4xf"},"outputs":[],"source":["# problem 1에서 배치사이즈를 키웠을때 성능이 향상되어 problem2에서도 배치사이즈가 커졌을 때 성능이 향상될지 궁금함. \n","\n","batch_size_3 = 256\n","learning_rate_3 = 0.0001\n","num_epoch = 50\n","\n","trainloader_3 = DataLoader(trainset, batch_size = batch_size_3)\n","testloader_3 = DataLoader(testset, batch_size = batch_size_3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZ-ak4mvE_vS"},"outputs":[],"source":["class AlexNet_model3(nn.Module): #Alexnet_model2와 구현 방식은 동일함\n","    def __init__(self):\n","        super(AlexNet_model3, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, 7),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2),\n","            nn.Conv2d(64, 192, 7, padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2),\n","            nn.Conv2d(192, 384, 7, padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(384, 256, 5, padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2))\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(256 * 6 * 6,1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(1024,512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10))\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(-1, 256 * 6 * 6)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IOJN8d5ZFDQX"},"outputs":[],"source":["model3 = AlexNet_model3().to(device)\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model3.parameters(), lr = learning_rate_3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FOXj9J1FGNq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"545cdcd5-6c48-4e0d-95a7-9a39f5a01983","executionInfo":{"status":"ok","timestamp":1655027966505,"user_tz":-540,"elapsed":397156,"user":{"displayName":"강민정","userId":"10148478567047156743"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.2415, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.5325, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.2187, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.8718, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.5827, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]}],"source":["for i in range(num_epoch):\n","    for j, [image, label] in enumerate(trainloader_3):\n","        x = image.to(device)\n","        y_ = label.to(device)\n","\n","        optimizer.zero_grad()\n","        output = model3.forward(x)\n","        loss = loss_func(output, y_)\n","        loss.backward()\n","        optimizer.step()\n","    if i % 10 == 0:\n","        print(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjvxnlMCFHGa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655027974952,"user_tz":-540,"elapsed":8466,"user":{"displayName":"강민정","userId":"10148478567047156743"}},"outputId":"7f4d0d6a-3df5-4be1-c572-9a9047156751"},"outputs":[{"output_type":"stream","name":"stdout","text":["model3 accuracy :  55.9375\n"]}],"source":["correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    model3.eval()\n","    for data in testloader_3:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        outputs = model3(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print(\"model3 accuracy : \", 100* correct / total)"]},{"cell_type":"markdown","source":["Problem 2 - 시도 4. Alexnet 구현 \n","\n","\n","*   padding 사용\n","*   Conv2d, Maxpool 추가\n","\n"],"metadata":{"id":"8SFnrnH6DTAh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HN_WIsOowAEc"},"outputs":[],"source":["# 처음 Alexnet에서 합성곱, 최대풀링, ReLU층을 추가하면 성능이 더 향상될까 궁금하여 추가해봄.\n","\n","batch_size_4 = 32\n","learning_rate_4 = 0.0001\n","num_epoch = 50\n","\n","trainloader_4 = DataLoader(trainset, batch_size = batch_size_4)\n","testloader_4 = DataLoader(testset, batch_size = batch_size_4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1eI1MLkcwAEc"},"outputs":[],"source":["class AlexNet_model4(nn.Module):\n","    def __init__(self):\n","        super(AlexNet_model4, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, 7), #[batch_size, 64, 90, 90]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2), #[batch_size, 64, 45, 45]\n","            nn.Conv2d(64, 192, 7, padding = 1), #[batch_size, 192, 41, 41]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2), #[batch_size, 192, 20, 20]\n","            nn.Conv2d(192, 384, 7, padding = 1), #[batch_size, 384, 16, 16]\n","            nn.ReLU(),\n","            nn.Conv2d(384, 768, 3, padding = 1), #추가 [batch_size, 768, 16, 16]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2), #추가 [batch_size, 768, 8, 8]\n","            nn.Conv2d(768, 384, 3, padding = 1), #추가 [batch_size, 384, 8, 8]\n","            nn.ReLU(),\n","            nn.Conv2d(384, 256, 5, padding = 1),  #[batch_size, 256, 6, 6]\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3), #[batch_size, 256, 6, 6]\n","            nn.ReLU(), #추가\n","            nn.MaxPool2d(2,2), #추가 [batch_size, 256, 3, 3]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2)) #[batch_size, 256, 1, 1]\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(256, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10))\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PvVgASilwAEd"},"outputs":[],"source":["model4 = AlexNet_model4().to(device)\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model4.parameters(), lr = learning_rate_4)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655105872791,"user_tz":-540,"elapsed":743366,"user":{"displayName":"장승희","userId":"11538399271208795766"}},"outputId":"6153c9e5-9ee4-40ce-f837-a6f791c1f884","id":"03bi_vcPwAEd"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.3764, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.1942, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.6200, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.1498, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]}],"source":["for i in range(num_epoch):\n","    for j, [image, label] in enumerate(trainloader_4):\n","        x = image.to(device)\n","        y_ = label.to(device)\n","\n","        optimizer.zero_grad()\n","        output = model4.forward(x)\n","        loss = loss_func(output, y_)\n","        loss.backward()\n","        optimizer.step()\n","    if i % 10 == 0:\n","        print(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655105885353,"user_tz":-540,"elapsed":12578,"user":{"displayName":"장승희","userId":"11538399271208795766"}},"outputId":"6200fd05-958e-43b7-b70d-0205b21fff72","id":"lgPsxfj7wAEe"},"outputs":[{"output_type":"stream","name":"stdout","text":["model4 accuracy :  58.1125\n"]}],"source":["correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    model4.eval()\n","    for data in testloader_4:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        outputs = model4(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print(\"model4 accuracy : \", 100 * correct / total)"]},{"cell_type":"markdown","metadata":{"id":"rqMoUifhGHRy"},"source":["# Problem 2 결과\n","최종 성능 58.1125%로 model4 (Alexnet 변형, padding = 1, batch size = 32, 합성곱 및 최대풀링층 추가)에서 가장 높은 성능을 기록함."]}]}